{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meetup Lublin 29.05.19\n",
    "\n",
    "# Analiza danych w Apache Spark\n",
    "\n",
    "\n",
    "<div style=\"text-align: right\">\n",
    "<b>Patryk Pilarski</b><br>\n",
    "1patryk.pilarski@gmail.com<br>\n",
    "p.pilarski@sages.com.pl\n",
    "</div>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Spark\n",
    "\n",
    "Apache Spark to silnik do obliczeń rozproszonych na licencji open-source. Pierwotnie powstał na Berkley, po czym przekazano go do Apache Software Foundation gdzie jest od tamtej pory utrzymywany i rozwijany. Spark oferuje interfejs pozwalający na programowanie obliczeń na klastrach z domyślną paralelizacją oraz odpornością na awarie.\n",
    "\n",
    "Ze Sparkiem pracować możemy w Scali, Pythonie, Javie oraz R.\n",
    "\n",
    "**Komponenty Sparka:**\n",
    "\n",
    "![title](spark-stack.png)\n",
    "\n",
    "* Spark \"core\" - podstawa Sparka z podstawową abstrakcją danych nazywaną RDD\n",
    "* Spark SQL - komponent pozwalający na operowanie na ustrukturyzowanych danych z wykorzystaniem operacji znanych z SQL\n",
    "* Spark MLlib - komponent zawierający algorytmy ML dostępne w Sparku\n",
    "* Spark Streaming - moduł pozwalający na pracę ze strumnieniami danych\n",
    "* Spark GraphX - komponent do pracy z grafami\n",
    "\n",
    "**Architektura Sparka:**\n",
    "\n",
    "![title](cluster-overview.png)\n",
    "\n",
    "* driver - proces uruchamiający główną funkcję aplikacji i tworzący SparkContext\n",
    "* executor(y) - proces uruchomiony dla aplikacji w węźle roboczym (worker node), który uruchamia zadania i przechowuje dane w pamięci lub na dysku. Każda aplikacja ma własne executory\n",
    "* cluster manager - dostępne opcje: YARN, Mesos, Kubernetes, Standalone\n",
    "\n",
    "**SparkContext:**\n",
    "* punkt wejścia do pracy ze Sparkiem\n",
    "* koordynuje procesy na klastrze\n",
    "* zatrzymanie SparkContextu == zatrzymanie działania aplikacji\n",
    "* zwykle nazywany `sc`\n",
    "* kroki niezbędne do utworzenia SparkContextu w pySparku:\n",
    "\n",
    "> import pyspark<br>\n",
    "> sc = pyspark.SparkContext(appName=\"my_app\")\n",
    "\n",
    "**SparkSession:**\n",
    "* wprowadzony w Spark 2.0\n",
    "* składa się ze SparkContextu, SQLContextu oraz HiveContext\n",
    "* zwykle nazywany `spark`\n",
    "* kroki niezbędne do utworzenia SparkSession w pySparku:\n",
    "\n",
    "> from pyspark.sql import SparkSession<br>\n",
    "> spark = SparkSession.builder.appName('my_app').getOrCreate()\n",
    "\n",
    "\n",
    "**RDD:**\n",
    "* podstawowa abstrakcja danych w Sparku\n",
    "* R - resilient\n",
    "* D - distributed\n",
    "* D - dataset\n",
    "* Matei Zharia, et al. `Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing`\n",
    "* immutable\n",
    "* in-memory\n",
    "* lazy evaluated\n",
    "* parallel\n",
    "* dwa typy operacji: akcje i transformacje\n",
    "\n",
    "\n",
    "[Dokumentacja](https://spark.apache.org/docs/latest/api/python/pyspark.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"demo_rdd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"MobyDick.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MOBY DICK;',\n",
       " '',\n",
       " '',\n",
       " 'or, THE WHALE.',\n",
       " '',\n",
       " '',\n",
       " 'CHAPTER 1. Loomings.',\n",
       " '',\n",
       " 'Call me Ishmael. Some years ago—never mind how long precisely—having',\n",
       " 'little or no money in my purse, and nothing particular to interest me on',\n",
       " 'shore, I thought I would sail about a little and see the watery part of',\n",
       " 'the world. It is a way I have of driving off the spleen and regulating',\n",
       " 'the circulation. Whenever I find myself growing grim about the mouth;',\n",
       " 'whenever it is a damp, drizzly November in my soul; whenever I find',\n",
       " 'myself involuntarily pausing before coffin warehouses, and bringing up',\n",
       " 'the rear of every funeral I meet; and especially whenever my hypos get',\n",
       " 'such an upper hand of me, that it requires a strong moral principle to',\n",
       " 'prevent me from deliberately stepping into the street, and methodically',\n",
       " 'knocking people’s hats off—then, I account it high time to get to',\n",
       " 'sea as soon as I can. This is my substitute for pistol and ball. With']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moby dick;',\n",
       " '',\n",
       " '',\n",
       " 'or, the whale.',\n",
       " '',\n",
       " '',\n",
       " 'chapter 1. loomings.',\n",
       " '',\n",
       " 'call me ishmael. some years ago—never mind how long precisely—having',\n",
       " 'little or no money in my purse, and nothing particular to interest me on',\n",
       " 'shore, i thought i would sail about a little and see the watery part of',\n",
       " 'the world. it is a way i have of driving off the spleen and regulating',\n",
       " 'the circulation. whenever i find myself growing grim about the mouth;',\n",
       " 'whenever it is a damp, drizzly november in my soul; whenever i find',\n",
       " 'myself involuntarily pausing before coffin warehouses, and bringing up',\n",
       " 'the rear of every funeral i meet; and especially whenever my hypos get',\n",
       " 'such an upper hand of me, that it requires a strong moral principle to',\n",
       " 'prevent me from deliberately stepping into the street, and methodically',\n",
       " 'knocking people’s hats off—then, i account it high time to get to',\n",
       " 'sea as soon as i can. this is my substitute for pistol and ball. with']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda x: x.lower()).take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 14161),\n",
       " ('of', 6549),\n",
       " ('and', 6286),\n",
       " ('a', 4566),\n",
       " ('to', 4564),\n",
       " ('in', 4085),\n",
       " ('', 3560),\n",
       " ('that', 2873),\n",
       " ('his', 2479),\n",
       " ('it', 2288),\n",
       " ('i', 1832),\n",
       " ('with', 1729),\n",
       " ('but', 1728),\n",
       " ('as', 1700),\n",
       " ('he', 1697),\n",
       " ('is', 1687),\n",
       " ('was', 1617),\n",
       " ('for', 1581),\n",
       " ('all', 1456),\n",
       " ('this', 1381)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.flatMap(lambda x: x.lower().split(\" \"))\\\n",
    ".map(lambda x: (x.strip(\".,;:?!-\"), 1))\\\n",
    ".reduceByKey(lambda x,y: x+y)\\\n",
    ".takeOrdered(20, lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataFrame:**\n",
    "* abstrakcja danych z modułu Spark SQL - u podstaw leżą RDD\n",
    "* immutable\n",
    "* in-memory\n",
    "* resilient\n",
    "* distributed\n",
    "* parallel\n",
    "* przechowuje dodatkowe informacje o strukturze danych (schema)\n",
    "* rozproszona kolekcja wierszy z nazwanymi kolumnami\n",
    "* optymalizowane przez Catalyst Optymizer\n",
    "* pozwala na pracę z danymi wykorzysując zapytania znane z SQL/Hive\n",
    "\n",
    "[Dokumentacja](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.ml import feature, classification, evaluation, Pipeline\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .appName('DataFrame')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = spark.read.csv(\"iris.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| setosa|\n",
      "|         5.4|        3.7|         1.5|        0.2| setosa|\n",
      "|         4.8|        3.4|         1.6|        0.2| setosa|\n",
      "|         4.8|        3.0|         1.4|        0.1| setosa|\n",
      "|         4.3|        3.0|         1.1|        0.1| setosa|\n",
      "|         5.8|        4.0|         1.2|        0.2| setosa|\n",
      "|         5.7|        4.4|         1.5|        0.4| setosa|\n",
      "|         5.4|        3.9|         1.3|        0.4| setosa|\n",
      "|         5.1|        3.5|         1.4|        0.3| setosa|\n",
      "|         5.7|        3.8|         1.7|        0.3| setosa|\n",
      "|         5.1|        3.8|         1.5|        0.3| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|species|\n",
      "+------------+-----------+-------+\n",
      "|         5.1|        3.5| setosa|\n",
      "|         4.9|        3.0| setosa|\n",
      "|         4.7|        3.2| setosa|\n",
      "|         4.6|        3.1| setosa|\n",
      "|         5.0|        3.6| setosa|\n",
      "|         5.4|        3.9| setosa|\n",
      "|         4.6|        3.4| setosa|\n",
      "|         5.0|        3.4| setosa|\n",
      "|         4.4|        2.9| setosa|\n",
      "|         4.9|        3.1| setosa|\n",
      "|         5.4|        3.7| setosa|\n",
      "|         4.8|        3.4| setosa|\n",
      "|         4.8|        3.0| setosa|\n",
      "|         4.3|        3.0| setosa|\n",
      "|         5.8|        4.0| setosa|\n",
      "|         5.7|        4.4| setosa|\n",
      "|         5.4|        3.9| setosa|\n",
      "|         5.1|        3.5| setosa|\n",
      "|         5.7|        3.8| setosa|\n",
      "|         5.1|        3.8| setosa|\n",
      "+------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris.select(\"sepal_length\", \"sepal_width\", \"species\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.createOrReplaceTempView(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|species|\n",
      "+------------+-----------+-------+\n",
      "|         5.1|        3.5| setosa|\n",
      "|         4.9|        3.0| setosa|\n",
      "|         4.7|        3.2| setosa|\n",
      "|         4.6|        3.1| setosa|\n",
      "|         5.0|        3.6| setosa|\n",
      "|         5.4|        3.9| setosa|\n",
      "|         4.6|        3.4| setosa|\n",
      "|         5.0|        3.4| setosa|\n",
      "|         4.4|        2.9| setosa|\n",
      "|         4.9|        3.1| setosa|\n",
      "|         5.4|        3.7| setosa|\n",
      "|         4.8|        3.4| setosa|\n",
      "|         4.8|        3.0| setosa|\n",
      "|         4.3|        3.0| setosa|\n",
      "|         5.8|        4.0| setosa|\n",
      "|         5.7|        4.4| setosa|\n",
      "|         5.4|        3.9| setosa|\n",
      "|         5.1|        3.5| setosa|\n",
      "|         5.7|        3.8| setosa|\n",
      "|         5.1|        3.8| setosa|\n",
      "+------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select sepal_length, sepal_width, species from iris\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+------------------+-----------------+------------------+\n",
      "|   species|avg(sepal_length)|  avg(sepal_width)|avg(petal_length)|  avg(petal_width)|\n",
      "+----------+-----------------+------------------+-----------------+------------------+\n",
      "| virginica|6.587999999999998|2.9739999999999998|            5.552|             2.026|\n",
      "|versicolor|            5.936|2.7700000000000005|             4.26|1.3259999999999998|\n",
      "|    setosa|5.005999999999999|3.4180000000000006|            1.464|0.2439999999999999|\n",
      "+----------+-----------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris.groupBy(\"species\").avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+------------------+-----------------+------------------+\n",
      "|   species|avg(sepal_length)|  avg(sepal_width)|avg(petal_length)|  avg(petal_width)|\n",
      "+----------+-----------------+------------------+-----------------+------------------+\n",
      "| virginica|6.587999999999998|2.9739999999999998|            5.552|             2.026|\n",
      "|versicolor|            5.936|2.7700000000000005|             4.26|1.3259999999999998|\n",
      "|    setosa|5.005999999999999|3.4180000000000006|            1.464|0.2439999999999999|\n",
      "+----------+-----------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = \"\"\"select species, avg(sepal_length), avg(sepal_width), avg(petal_length), avg(petal_width) \n",
    "from iris group by species\"\"\"\n",
    "\n",
    "spark.sql(q).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_iris = iris.groupBy(\"species\").avg().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pd_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>avg(sepal_length)</th>\n",
       "      <th>avg(sepal_width)</th>\n",
       "      <th>avg(petal_length)</th>\n",
       "      <th>avg(petal_width)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virginica</td>\n",
       "      <td>6.588</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.552</td>\n",
       "      <td>2.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>5.936</td>\n",
       "      <td>2.770</td>\n",
       "      <td>4.260</td>\n",
       "      <td>1.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setosa</td>\n",
       "      <td>5.006</td>\n",
       "      <td>3.418</td>\n",
       "      <td>1.464</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      species  avg(sepal_length)  avg(sepal_width)  avg(petal_length)  \\\n",
       "0   virginica              6.588             2.974              5.552   \n",
       "1  versicolor              5.936             2.770              4.260   \n",
       "2      setosa              5.006             3.418              1.464   \n",
       "\n",
       "   avg(petal_width)  \n",
       "0             2.026  \n",
       "1             1.326  \n",
       "2             0.244  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Porównanie pandas vs pyspark lokalnie\n",
    "\n",
    "Query 1. SELECT max(ss_list_price) FROM store_sales\n",
    "<img src=\"image2.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "Query 2. SELECT count(distinct ss_customer_sk) FROM store_sales\n",
    "<img src=\"image1.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "Query 3. SELECT sum(ss_net_profit) FROM store_sales GROUP BY ss_store_sk\n",
    "<img src=\"image4.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "Artykuł Databricks: [link](https://databricks.com/blog/2018/05/03/benchmarking-apache-spark-on-a-single-node-machine.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ML:**\n",
    "* Transformer - algorytm przekształcający wejściowy DF w inny DF, np. wytrenowany model ML tworzący nowy DF zawierający predykcje (transform)\n",
    "* Estymator - algorytm który na podstawie DF tworzy transformer (fit)\n",
    "* Pipeline - szeregowe połączenie transformerów i estymatorów w celu utworzenia przepływu (workflow)\n",
    "\n",
    "[Dokumentacja](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| setosa|\n",
      "|         5.4|        3.7|         1.5|        0.2| setosa|\n",
      "|         4.8|        3.4|         1.6|        0.2| setosa|\n",
      "|         4.8|        3.0|         1.4|        0.1| setosa|\n",
      "|         4.3|        3.0|         1.1|        0.1| setosa|\n",
      "|         5.8|        4.0|         1.2|        0.2| setosa|\n",
      "|         5.7|        4.4|         1.5|        0.4| setosa|\n",
      "|         5.4|        3.9|         1.3|        0.4| setosa|\n",
      "|         5.1|        3.5|         1.4|        0.3| setosa|\n",
      "|         5.7|        3.8|         1.7|        0.3| setosa|\n",
      "|         5.1|        3.8|         1.5|        0.3| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podział na zbiór uczący i testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw, test_raw = iris.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "+----------+-----+\n",
      "|   species|count|\n",
      "+----------+-----+\n",
      "| virginica|   38|\n",
      "|versicolor|   37|\n",
      "|    setosa|   39|\n",
      "+----------+-----+\n",
      "\n",
      "Test\n",
      "+----------+-----+\n",
      "|   species|count|\n",
      "+----------+-----+\n",
      "| virginica|   12|\n",
      "|versicolor|   13|\n",
      "|    setosa|   11|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\")\n",
    "train_raw.groupBy(\"species\").count().show()\n",
    "\n",
    "print(\"Test\")\n",
    "test_raw.groupBy(\"species\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przekształcenie zmiennej celu do postaci numerycznej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "strIdx = feature.StringIndexer(inputCol=\"species\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "strIdx_trans = strIdx.fit(train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+----------+-----+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|   species|label|\n",
      "+------------+-----------+------------+-----------+----------+-----+\n",
      "|         4.3|        3.0|         1.1|        0.1|    setosa|  0.0|\n",
      "|         4.5|        2.3|         1.3|        0.3|    setosa|  0.0|\n",
      "|         4.6|        3.1|         1.5|        0.2|    setosa|  0.0|\n",
      "|         4.6|        3.2|         1.4|        0.2|    setosa|  0.0|\n",
      "|         4.6|        3.4|         1.4|        0.3|    setosa|  0.0|\n",
      "|         4.6|        3.6|         1.0|        0.2|    setosa|  0.0|\n",
      "|         4.7|        3.2|         1.3|        0.2|    setosa|  0.0|\n",
      "|         4.7|        3.2|         1.6|        0.2|    setosa|  0.0|\n",
      "|         4.8|        3.0|         1.4|        0.1|    setosa|  0.0|\n",
      "|         4.8|        3.0|         1.4|        0.3|    setosa|  0.0|\n",
      "|         4.8|        3.4|         1.6|        0.2|    setosa|  0.0|\n",
      "|         4.8|        3.4|         1.9|        0.2|    setosa|  0.0|\n",
      "|         4.9|        2.5|         4.5|        1.7| virginica|  1.0|\n",
      "|         4.9|        3.0|         1.4|        0.2|    setosa|  0.0|\n",
      "|         4.9|        3.1|         1.5|        0.1|    setosa|  0.0|\n",
      "|         4.9|        3.1|         1.5|        0.1|    setosa|  0.0|\n",
      "|         4.9|        3.1|         1.5|        0.1|    setosa|  0.0|\n",
      "|         5.0|        2.0|         3.5|        1.0|versicolor|  2.0|\n",
      "|         5.0|        2.3|         3.3|        1.0|versicolor|  2.0|\n",
      "|         5.0|        3.0|         1.6|        0.2|    setosa|  0.0|\n",
      "+------------+-----------+------------+-----------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = strIdx_trans.transform(train_raw)\n",
    "train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotowanie zmiennych objaśniających"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectA = feature.VectorAssembler(inputCols=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"], \n",
    "                                outputCol=\"feats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+----------+-----+-----------------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|   species|label|            feats|\n",
      "+------------+-----------+------------+-----------+----------+-----+-----------------+\n",
      "|         4.3|        3.0|         1.1|        0.1|    setosa|  0.0|[4.3,3.0,1.1,0.1]|\n",
      "|         4.5|        2.3|         1.3|        0.3|    setosa|  0.0|[4.5,2.3,1.3,0.3]|\n",
      "|         4.6|        3.1|         1.5|        0.2|    setosa|  0.0|[4.6,3.1,1.5,0.2]|\n",
      "|         4.6|        3.2|         1.4|        0.2|    setosa|  0.0|[4.6,3.2,1.4,0.2]|\n",
      "|         4.6|        3.4|         1.4|        0.3|    setosa|  0.0|[4.6,3.4,1.4,0.3]|\n",
      "|         4.6|        3.6|         1.0|        0.2|    setosa|  0.0|[4.6,3.6,1.0,0.2]|\n",
      "|         4.7|        3.2|         1.3|        0.2|    setosa|  0.0|[4.7,3.2,1.3,0.2]|\n",
      "|         4.7|        3.2|         1.6|        0.2|    setosa|  0.0|[4.7,3.2,1.6,0.2]|\n",
      "|         4.8|        3.0|         1.4|        0.1|    setosa|  0.0|[4.8,3.0,1.4,0.1]|\n",
      "|         4.8|        3.0|         1.4|        0.3|    setosa|  0.0|[4.8,3.0,1.4,0.3]|\n",
      "|         4.8|        3.4|         1.6|        0.2|    setosa|  0.0|[4.8,3.4,1.6,0.2]|\n",
      "|         4.8|        3.4|         1.9|        0.2|    setosa|  0.0|[4.8,3.4,1.9,0.2]|\n",
      "|         4.9|        2.5|         4.5|        1.7| virginica|  1.0|[4.9,2.5,4.5,1.7]|\n",
      "|         4.9|        3.0|         1.4|        0.2|    setosa|  0.0|[4.9,3.0,1.4,0.2]|\n",
      "|         4.9|        3.1|         1.5|        0.1|    setosa|  0.0|[4.9,3.1,1.5,0.1]|\n",
      "|         4.9|        3.1|         1.5|        0.1|    setosa|  0.0|[4.9,3.1,1.5,0.1]|\n",
      "|         4.9|        3.1|         1.5|        0.1|    setosa|  0.0|[4.9,3.1,1.5,0.1]|\n",
      "|         5.0|        2.0|         3.5|        1.0|versicolor|  2.0|[5.0,2.0,3.5,1.0]|\n",
      "|         5.0|        2.3|         3.3|        1.0|versicolor|  2.0|[5.0,2.3,3.3,1.0]|\n",
      "|         5.0|        3.0|         1.6|        0.2|    setosa|  0.0|[5.0,3.0,1.6,0.2]|\n",
      "+------------+-----------+------------+-----------+----------+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = vectA.transform(train)\n",
    "train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przeskalowanie zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = feature.StandardScaler(inputCol=\"feats\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_trans = scaler.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+----------+-----+-----------------+--------------------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|   species|label|            feats|            features|\n",
      "+------------+-----------+------------+-----------+----------+-----+-----------------+--------------------+\n",
      "|         4.3|        3.0|         1.1|        0.1|    setosa|  0.0|[4.3,3.0,1.1,0.1]|[5.25128172868887...|\n",
      "|         4.5|        2.3|         1.3|        0.3|    setosa|  0.0|[4.5,2.3,1.3,0.3]|[5.49552739048835...|\n",
      "|         4.6|        3.1|         1.5|        0.2|    setosa|  0.0|[4.6,3.1,1.5,0.2]|[5.61765022138809...|\n",
      "|         4.6|        3.2|         1.4|        0.2|    setosa|  0.0|[4.6,3.2,1.4,0.2]|[5.61765022138809...|\n",
      "|         4.6|        3.4|         1.4|        0.3|    setosa|  0.0|[4.6,3.4,1.4,0.3]|[5.61765022138809...|\n",
      "|         4.6|        3.6|         1.0|        0.2|    setosa|  0.0|[4.6,3.6,1.0,0.2]|[5.61765022138809...|\n",
      "|         4.7|        3.2|         1.3|        0.2|    setosa|  0.0|[4.7,3.2,1.3,0.2]|[5.73977305228784...|\n",
      "|         4.7|        3.2|         1.6|        0.2|    setosa|  0.0|[4.7,3.2,1.6,0.2]|[5.73977305228784...|\n",
      "|         4.8|        3.0|         1.4|        0.1|    setosa|  0.0|[4.8,3.0,1.4,0.1]|[5.86189588318758...|\n",
      "|         4.8|        3.0|         1.4|        0.3|    setosa|  0.0|[4.8,3.0,1.4,0.3]|[5.86189588318758...|\n",
      "|         4.8|        3.4|         1.6|        0.2|    setosa|  0.0|[4.8,3.4,1.6,0.2]|[5.86189588318758...|\n",
      "|         4.8|        3.4|         1.9|        0.2|    setosa|  0.0|[4.8,3.4,1.9,0.2]|[5.86189588318758...|\n",
      "|         4.9|        2.5|         4.5|        1.7| virginica|  1.0|[4.9,2.5,4.5,1.7]|[5.98401871408732...|\n",
      "|         4.9|        3.0|         1.4|        0.2|    setosa|  0.0|[4.9,3.0,1.4,0.2]|[5.98401871408732...|\n",
      "|         4.9|        3.1|         1.5|        0.1|    setosa|  0.0|[4.9,3.1,1.5,0.1]|[5.98401871408732...|\n",
      "|         4.9|        3.1|         1.5|        0.1|    setosa|  0.0|[4.9,3.1,1.5,0.1]|[5.98401871408732...|\n",
      "|         4.9|        3.1|         1.5|        0.1|    setosa|  0.0|[4.9,3.1,1.5,0.1]|[5.98401871408732...|\n",
      "|         5.0|        2.0|         3.5|        1.0|versicolor|  2.0|[5.0,2.0,3.5,1.0]|[6.10614154498706...|\n",
      "|         5.0|        2.3|         3.3|        1.0|versicolor|  2.0|[5.0,2.3,3.3,1.0]|[6.10614154498706...|\n",
      "|         5.0|        3.0|         1.6|        0.2|    setosa|  0.0|[5.0,3.0,1.6,0.2]|[6.10614154498706...|\n",
      "+------------+-----------+------------+-----------+----------+-----+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = scaler_trans.transform(train)\n",
    "train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utworzenie i wytrenowanie modelu regresji logistycznej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = classification.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mod = lr.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotowanie zbioru testowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+----------+-----+-----------------+--------------------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|   species|label|            feats|            features|\n",
      "+------------+-----------+------------+-----------+----------+-----+-----------------+--------------------+\n",
      "|         4.4|        2.9|         1.4|        0.2|    setosa|  0.0|[4.4,2.9,1.4,0.2]|[5.37340455958861...|\n",
      "|         4.4|        3.0|         1.3|        0.2|    setosa|  0.0|[4.4,3.0,1.3,0.2]|[5.37340455958861...|\n",
      "|         4.4|        3.2|         1.3|        0.2|    setosa|  0.0|[4.4,3.2,1.3,0.2]|[5.37340455958861...|\n",
      "|         4.8|        3.1|         1.6|        0.2|    setosa|  0.0|[4.8,3.1,1.6,0.2]|[5.86189588318758...|\n",
      "|         4.9|        2.4|         3.3|        1.0|versicolor|  2.0|[4.9,2.4,3.3,1.0]|[5.98401871408732...|\n",
      "|         5.0|        3.3|         1.4|        0.2|    setosa|  0.0|[5.0,3.3,1.4,0.2]|[6.10614154498706...|\n",
      "|         5.0|        3.4|         1.6|        0.4|    setosa|  0.0|[5.0,3.4,1.6,0.4]|[6.10614154498706...|\n",
      "|         5.0|        3.5|         1.3|        0.3|    setosa|  0.0|[5.0,3.5,1.3,0.3]|[6.10614154498706...|\n",
      "|         5.1|        3.4|         1.5|        0.2|    setosa|  0.0|[5.1,3.4,1.5,0.2]|[6.22826437588680...|\n",
      "|         5.1|        3.5|         1.4|        0.2|    setosa|  0.0|[5.1,3.5,1.4,0.2]|[6.22826437588680...|\n",
      "|         5.4|        3.9|         1.3|        0.4|    setosa|  0.0|[5.4,3.9,1.3,0.4]|[6.59463286858603...|\n",
      "|         5.4|        3.9|         1.7|        0.4|    setosa|  0.0|[5.4,3.9,1.7,0.4]|[6.59463286858603...|\n",
      "|         5.5|        2.4|         3.7|        1.0|versicolor|  2.0|[5.5,2.4,3.7,1.0]|[6.71675569948577...|\n",
      "|         5.5|        2.5|         4.0|        1.3|versicolor|  2.0|[5.5,2.5,4.0,1.3]|[6.71675569948577...|\n",
      "|         5.6|        2.5|         3.9|        1.1|versicolor|  2.0|[5.6,2.5,3.9,1.1]|[6.83887853038551...|\n",
      "|         5.6|        3.0|         4.1|        1.3|versicolor|  2.0|[5.6,3.0,4.1,1.3]|[6.83887853038551...|\n",
      "|         5.7|        2.5|         5.0|        2.0| virginica|  1.0|[5.7,2.5,5.0,2.0]|[6.96100136128525...|\n",
      "|         5.7|        2.8|         4.5|        1.3|versicolor|  2.0|[5.7,2.8,4.5,1.3]|[6.96100136128525...|\n",
      "|         5.8|        2.7|         5.1|        1.9| virginica|  1.0|[5.8,2.7,5.1,1.9]|[7.08312419218499...|\n",
      "|         5.9|        3.2|         4.8|        1.8|versicolor|  2.0|[5.9,3.2,4.8,1.8]|[7.20524702308473...|\n",
      "+------------+-----------+------------+-----------+----------+-----+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = strIdx_trans.transform(test_raw)\n",
    "test = vectA.transform(test)\n",
    "test = scaler_trans.transform(test)\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inferencja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+----------+\n",
      "|   species|label|            features|prediction|\n",
      "+----------+-----+--------------------+----------+\n",
      "|    setosa|  0.0|[5.37340455958861...|       0.0|\n",
      "|    setosa|  0.0|[5.37340455958861...|       0.0|\n",
      "|    setosa|  0.0|[5.37340455958861...|       0.0|\n",
      "|    setosa|  0.0|[5.86189588318758...|       0.0|\n",
      "|versicolor|  2.0|[5.98401871408732...|       2.0|\n",
      "|    setosa|  0.0|[6.10614154498706...|       0.0|\n",
      "|    setosa|  0.0|[6.10614154498706...|       0.0|\n",
      "|    setosa|  0.0|[6.10614154498706...|       0.0|\n",
      "|    setosa|  0.0|[6.22826437588680...|       0.0|\n",
      "|    setosa|  0.0|[6.22826437588680...|       0.0|\n",
      "|    setosa|  0.0|[6.59463286858603...|       0.0|\n",
      "|    setosa|  0.0|[6.59463286858603...|       0.0|\n",
      "|versicolor|  2.0|[6.71675569948577...|       2.0|\n",
      "|versicolor|  2.0|[6.71675569948577...|       2.0|\n",
      "|versicolor|  2.0|[6.83887853038551...|       2.0|\n",
      "|versicolor|  2.0|[6.83887853038551...|       2.0|\n",
      "| virginica|  1.0|[6.96100136128525...|       1.0|\n",
      "|versicolor|  2.0|[6.96100136128525...|       2.0|\n",
      "| virginica|  1.0|[7.08312419218499...|       1.0|\n",
      "|versicolor|  2.0|[7.20524702308473...|       1.0|\n",
      "+----------+-----+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = lr_mod.transform(test)\n",
    "pred.select(\"species\", \"label\", \"features\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utworzenie ewaluatora i ewaluacja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = evaluation.MulticlassClassificationEvaluator(metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.evaluate(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Stworzenie pipeline'u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "strIdx = feature.StringIndexer(inputCol=\"species\", outputCol=\"label\")\n",
    "vectA = feature.VectorAssembler(inputCols=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"], \n",
    "                                outputCol=\"feats\")\n",
    "scaler = feature.StandardScaler(inputCol=\"feats\", outputCol=\"features\")\n",
    "lr = classification.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(stages=[strIdx, vectA, scaler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mod = pipe.fit(train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+----------+\n",
      "|   species|label|            features|prediction|\n",
      "+----------+-----+--------------------+----------+\n",
      "|    setosa|  0.0|[5.37340455958861...|       0.0|\n",
      "|    setosa|  0.0|[5.37340455958861...|       0.0|\n",
      "|    setosa|  0.0|[5.37340455958861...|       0.0|\n",
      "|    setosa|  0.0|[5.86189588318758...|       0.0|\n",
      "|versicolor|  2.0|[5.98401871408732...|       2.0|\n",
      "|    setosa|  0.0|[6.10614154498706...|       0.0|\n",
      "|    setosa|  0.0|[6.10614154498706...|       0.0|\n",
      "|    setosa|  0.0|[6.10614154498706...|       0.0|\n",
      "|    setosa|  0.0|[6.22826437588680...|       0.0|\n",
      "|    setosa|  0.0|[6.22826437588680...|       0.0|\n",
      "|    setosa|  0.0|[6.59463286858603...|       0.0|\n",
      "|    setosa|  0.0|[6.59463286858603...|       0.0|\n",
      "|versicolor|  2.0|[6.71675569948577...|       2.0|\n",
      "|versicolor|  2.0|[6.71675569948577...|       2.0|\n",
      "|versicolor|  2.0|[6.83887853038551...|       2.0|\n",
      "|versicolor|  2.0|[6.83887853038551...|       2.0|\n",
      "| virginica|  1.0|[6.96100136128525...|       1.0|\n",
      "|versicolor|  2.0|[6.96100136128525...|       2.0|\n",
      "| virginica|  1.0|[7.08312419218499...|       1.0|\n",
      "|versicolor|  2.0|[7.20524702308473...|       1.0|\n",
      "+----------+-----+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_mod.transform(test_raw).select(\"species\", \"label\", \"features\", \"prediction\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
